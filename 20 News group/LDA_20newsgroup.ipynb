{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9fd269c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importació de llibreries per a modelatge, processament de text i validació\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier  # Classificador Gradient Boosting optimitzat\n",
    "\n",
    "# Càrrega del conjunt de dades '20 Newsgroups', una col·lecció de textos en anglès classificats per temes\n",
    "\n",
    "dades = fetch_20newsgroups(subset='all', remove=())  # Es carrega el conjunt complet, sense eliminar cap part\n",
    "\n",
    "# Es crea un DataFrame amb el text dels documents i la seva etiqueta numèrica\n",
    "df = pd.DataFrame({\n",
    "    'text': dades.data,\n",
    "    'etiqueta_original': dades.target\n",
    "})\n",
    "\n",
    "# S’afegeix una columna amb el nom de la categoria textual corresponent a cada etiqueta\n",
    "noms_categories = dades.target_names\n",
    "df['tema'] = df['etiqueta_original'].apply(lambda x: noms_categories[x])\n",
    "\n",
    "# Definició d'una variable binària \"esport\"\n",
    "# Classes positives: categories relacionades amb esports i motors\n",
    "\n",
    "categories_esport = ['rec.sport.baseball', 'rec.sport.hockey', 'rec.autos', 'rec.motorcycles']\n",
    "df['esport'] = df['tema'].apply(lambda x: 1 if x in categories_esport else 0)\n",
    "\n",
    "# Separació de les dades (X) i etiquetes binàries (y)\n",
    "\n",
    "X = df['text'].values\n",
    "y = df['esport'].values\n",
    "\n",
    "# Definició d’una llista de paraules buides personalitzada\n",
    "# Aquestes paraules seran ignorades durant la vectorització\n",
    "\n",
    "stopwords = [\n",
    "    'as', 'an', 'the', 'in', 'on', 'at', 'to', 'of', 'and', 'or',\n",
    "    'is', 'it', 'for', 'with', 'that', 'this', 'was', 'be',\n",
    "    'are', 'were', 'been', 'from', 'by', 'about', 'into', 'out',\n",
    "    'up', 'down', 'over', 'under', 'then', 'than', 'so', 'but', 'not'\n",
    "]\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "# Paràmetres a explorar: nombre de temes (k) per a LDA\n",
    "\n",
    "valors_k = [20]  # En aquest exemple, només es prova amb k = 20\n",
    "\n",
    "# Inicialització de la llista per emmagatzemar els resultats finals\n",
    "resultats = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "12f3b23b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteracio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteracio\n",
      "0.9640405288040741\n",
      "iteracio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteracio\n",
      "0.9694402047235843\n",
      "iteracio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [ ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteracio\n",
      "0.98127959001195\n",
      "iteracio\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": []
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteracio\n",
      "0.9795027103225513\n",
      "iteracio\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [ ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteracio\n",
      "0.9772453506913165\n",
      "[{'k': 20, 'auc_roc_mitjana': np.float64(0.9743016769106954)}]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Configuració de validació creuada  (5 particions)\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Bucle principal: per a cada valor de k (temes), es fa validació creuada\n",
    "# amb XGBoost entrenat sobre les representacions temàtiques LDA\n",
    "\n",
    "\n",
    "for k in valors_k:\n",
    "    puntuacions = []  # Llista per desar els AUCs de cada fold\n",
    "\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        # Separació en conjunt d'entrenament i de prova\n",
    "        X_train_raw, X_test_raw = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "\n",
    "        # Vectorització dels textos amb CountVectorizer\n",
    "        # Es limita a les 10.000 paraules més freqüents i es filtren les stopwords\n",
    "\n",
    "        vectoritzador = CountVectorizer(max_features=10000, stop_words=stopwords)\n",
    "        X_train_counts = vectoritzador.fit_transform(X_train_raw)\n",
    "        X_test_counts = vectoritzador.transform(X_test_raw)\n",
    "\n",
    "        # Reducció de dimensionalitat amb LDA (Latent Dirichlet Allocation)\n",
    "        # Cada document es representa com una distribució de probabilitats sobre k temes\n",
    "\n",
    "        lda = LatentDirichletAllocation(n_components=k, random_state=42)\n",
    "        X_train_topics = lda.fit_transform(X_train_counts)\n",
    "        X_test_topics = lda.transform(X_test_counts)\n",
    "\n",
    "        print(\"iteracio\")  # Missatge indicatiu de progrés\n",
    "\n",
    "        # Entrenament del model XGBoost (Gradient Boosting per classificació binària)\n",
    "        # Paràmetres comuns: profunditat màxima, nombre d'arbres, mètrica i semilla\n",
    "\n",
    "        model = XGBClassifier(\n",
    "            max_depth=6,\n",
    "            n_estimators=500,\n",
    "            use_label_encoder=False,  # Es desactiva per evitar warnings antics\n",
    "            eval_metric='logloss',\n",
    "            random_state=42\n",
    "        )\n",
    "        model.fit(X_train_topics, y_train)\n",
    "        print(\"iteracio\")\n",
    "        # Predicció de probabilitats i càlcul de la mètrica AUC-ROC\n",
    "        # Aquesta mètrica avalua la qualitat de la classificació probabilística\n",
    "\n",
    "        probabilitats = model.predict_proba(X_test_topics)[:, 1]\n",
    "        puntuacio = roc_auc_score(y_test, probabilitats)\n",
    "        puntuacions.append(puntuacio)\n",
    "        print(puntuacio)  # Impressió de la puntuació AUC del fold actual\n",
    "\n",
    "    # Emmagatzematge del valor mitjà d'AUC-ROC per a aquest valor de k\n",
    "\n",
    "    resultats.append({\n",
    "        'k': k,\n",
    "        'auc_roc_mitjana': np.mean(puntuacions)\n",
    "    })\n",
    "    print(resultats)  # Impressió de resultats acumulats\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
