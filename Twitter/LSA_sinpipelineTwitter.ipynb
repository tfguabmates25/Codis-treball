{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed744a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importació de llibreries per al processament de text,\n",
    "# reducció de dimensionalitat, classificació i validació\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# Càrrega del conjunt de dades pre-processat i reduït\n",
    "# Es tracta d'un subconjunt del corpus Sentiment140 amb textos i etiquetes\n",
    "\n",
    "df_reduït = pd.read_csv('twitter_reduït_Dataset.csv', encoding='latin-1')\n",
    "\n",
    "# Separació de les variables predictives (textos) i de la variable objectiu (sentiment)\n",
    "X = df_reduït['text'].values\n",
    "y = df_reduït['target'].values\n",
    "\n",
    "# Definició d’una llista de paraules buides personalitzades\n",
    "# Aquestes paraules es filtraran durant la vectorització per no aportar informació rellevant\n",
    "\n",
    "stopwords_personalitzades = [\n",
    "    'as', 'an', 'the', 'in', 'on', 'at', 'to', 'of', 'and', 'or',\n",
    "    'is', 'it', 'for', 'with', 'that', 'this', 'was', 'be',\n",
    "    'are', 'were', 'been', 'from', 'by', 'about', 'into', 'out',\n",
    "    'up', 'down', 'over', 'under', 'then', 'than', 'so', 'but', 'not'\n",
    "]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56c23859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteracio\n",
      "iteracio\n",
      "iteracio\n",
      "iteracio\n",
      "iteracio\n",
      "[{'k_components': 100, 'C': 1, 'auc_roc_mitjana': np.float64(0.763131953125)}]\n"
     ]
    }
   ],
   "source": [
    "# Definició dels paràmetres per a l’exploració mitjançant grid search\n",
    "# components_k: nombre de components latents a conservar amb SVD (LSA)\n",
    "# valors_C: valors del paràmetre de regularització per a regressió logística\n",
    "\n",
    "components_k = [100]  # nombre de components latents per a LSA (Truncated SVD)\n",
    "valors_C = [1]        # força de regularització per a la regressió logística\n",
    "\n",
    "# Inicialització de la llista per emmagatzemar els resultats per cada combinació\n",
    "resultats = []\n",
    "\n",
    "# Configuració de la validació creuada (5 particions)\n",
    "# Aquesta tècnica manté la distribució proporcional de les classes en cada fold\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Bucle principal sobre totes les combinacions de k (components LSA) i C (regularització)\n",
    "\n",
    "for k in components_k:\n",
    "    for C in valors_C:\n",
    "        puntuacions = []  # Llista per emmagatzemar AUC-ROC de cada fold\n",
    "\n",
    "        # Validació creuada estratificada\n",
    "        for train_idx, test_idx in cv.split(X, y):\n",
    "            # Separació de textos i etiquetes en entrenament i test\n",
    "            texts_train = X[train_idx]\n",
    "            texts_test = X[test_idx]\n",
    "            y_train = y[train_idx]\n",
    "            y_test = y[test_idx]\n",
    "\n",
    "            # Vectorització del text amb TF-IDF\n",
    "            # max_features: nombre màxim de paraules seleccionades per importància\n",
    "            # stop_words: llista de paraules buides a eliminar\n",
    "            # S'ajusta només amb el conjunt d'entrenament per evitar fuites\n",
    "\n",
    "            vectoritzador = TfidfVectorizer(max_features=10000, stop_words=stopwords_personalitzades)\n",
    "            X_train_tfidf = vectoritzador.fit_transform(texts_train)\n",
    "            X_test_tfidf = vectoritzador.transform(texts_test)\n",
    "\n",
    "            # Reducció de dimensionalitat amb Truncated SVD (LSA)\n",
    "            # Transforma els vectors TF-IDF en una representació temàtica més compacta\n",
    "\n",
    "            svd = TruncatedSVD(n_components=k, random_state=42)\n",
    "            X_train_lsa = svd.fit_transform(X_train_tfidf)\n",
    "            X_test_lsa = svd.transform(X_test_tfidf)\n",
    "\n",
    "            # Entrenament d'un model de regressió logística\n",
    "            # penalty='l2': regularització ridge\n",
    "            # C: invers de la força de regularització (menor valor → més regularització)\n",
    "            # class_weight='balanced': ajusta els pesos segons la distribució de classes\n",
    "\n",
    "            model = LogisticRegression(\n",
    "                penalty='l2',\n",
    "                C=C,\n",
    "                solver='lbfgs',\n",
    "                max_iter=100,\n",
    "                random_state=42,\n",
    "            )\n",
    "            model.fit(X_train_lsa, y_train)\n",
    "\n",
    "            # Predicció de probabilitats per a la classe positiva\n",
    "            # i càlcul de la mètrica AUC-ROC per al fold actual\n",
    "\n",
    "            probs = model.predict_proba(X_test_lsa)[:, 1]\n",
    "            auc = roc_auc_score(y_test, probs)\n",
    "            puntuacions.append(auc)\n",
    "            print(\"iteracio\")\n",
    "\n",
    "        # Emmagatzematge dels resultats mitjans per a la combinació actual (k, C)\n",
    "\n",
    "        resultats.append({\n",
    "            'k_components': k,\n",
    "            'C': C,\n",
    "            'auc_roc_mitjana': np.mean(puntuacions)\n",
    "        })\n",
    "\n",
    "        # Impressió dels resultats parcials per fer seguiment\n",
    "        print(resultats)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
